# â™Ÿï¸ chessMania â€” Chess MLOps Pipeline

> From raw PGN ingestion to Transformer-powered next-move prediction, with full MLOps lifecycle coverage.

[![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Overview

**chessMania** is an end-to-end MLOps project that demonstrates every stage of the machine learning lifecycle using chess game data. It starts with a **tabular ML baseline (XGBoost)** and scales into **Transformer-based sequence modelling**, showcasing research engineering rigor and modern ML operations practices.

| Component | Implementation |
|---|---|
| **Storage** | MinIO (PGN / JSON / Parquet) |
| **Orchestration** | Apache Airflow (PGN parsing â†’ Feature & Sequence extraction) |
| **Data Validation** | Great Expectations |
| **Data Warehouse** | PostgreSQL |
| **ML Framework** | XGBoost â†’ GPT-style Transformer with LoRA/QLoRA |
| **Experiment Tracking** | MLflow (Accuracy, F1, AUC, Perplexity, MFU) |
| **Serving** | FastAPI + Uvicorn (Next-move prediction, Win probability) |
| **Monitoring** | Evidently AI (Feature drift + Structural/Move-sequence drift) |
| **Containerisation** | Docker + Docker Compose |

---

## ğŸ—ï¸ Project Structure

```
chessMania/
â”‚
â”œâ”€â”€ README.md                          # â† You are here
â”œâ”€â”€ pyproject.toml                     # Dependencies & build config
â”œâ”€â”€ Makefile                           # Developer shortcuts
â”œâ”€â”€ Dockerfile                         # API container image
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example                       # Environment variable template
â”œâ”€â”€ .pre-commit-config.yaml            # Linting & formatting hooks
â”œâ”€â”€ alembic.ini                        # Database migration config
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ src/                               # â•â•â• APPLICATION CODE â•â•â•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                        # Centralised configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py                #   Hydra/OmegaConf loader
â”‚   â”‚   â””â”€â”€ config.yaml               #   All settings (storage, models, servingâ€¦)
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                     # â”€â”€ Stage 1: Data Ingestion â”€â”€
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ minio_client.py            #   MinIO upload / download helpers
â”‚   â”‚   â”œâ”€â”€ pgn_parser.py             #   Parse PGN â†’ structured dicts
â”‚   â”‚   â”œâ”€â”€ db.py                      #   SQLAlchemy models (PostgreSQL)
â”‚   â”‚   â”œâ”€â”€ ingest_pgn.py             #   End-to-end ingestion entry-point
â”‚   â”‚   â””â”€â”€ validate.py               #   Great Expectations quality checks
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/                 # â”€â”€ Stage 2: Preprocessing â”€â”€
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tabular_features.py       #   XGBoost feature extraction
â”‚   â”‚   â”œâ”€â”€ sequence_tokenizer.py     #   SAN â†’ integer token IDs
â”‚   â”‚   â”œâ”€â”€ dataset.py                #   PyTorch Dataset / DataLoader
â”‚   â”‚   â””â”€â”€ splits.py                 #   Train / Val / Test splitting
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                        # â”€â”€ Stage 3: Model Development â”€â”€
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mlflow_utils.py           #   MLflow tracking helpers
â”‚   â”‚   â”œâ”€â”€ xgboost_trainer.py        #   XGBoost classifier training
â”‚   â”‚   â”œâ”€â”€ transformer_model.py      #   GPT-style causal LM architecture
â”‚   â”‚   â”œâ”€â”€ transformer_trainer.py    #   Training loop with LoRA/QLoRA
â”‚   â”‚   â””â”€â”€ registry.py              #   Save / load model artefacts
â”‚   â”‚
â”‚   â”œâ”€â”€ serving/                       # â”€â”€ Stage 4: Deployment & Serving â”€â”€
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                    #   FastAPI application & routes
â”‚   â”‚   â”œâ”€â”€ schemas.py                #   Pydantic request / response models
â”‚   â”‚   â””â”€â”€ inference.py              #   Inference helpers
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/                    # â”€â”€ Stage 5: Model Monitoring â”€â”€
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ generate_report.py        #   Evidently drift report generator
â”‚       â””â”€â”€ drift_detectors.py        #   Custom sequence-level drift checks
â”‚
â”œâ”€â”€ airflow/                           # â•â•â• ORCHESTRATION â•â•â•
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ chess_ingestion_dag.py     #   Daily: ingest â†’ validate â†’ features
â”‚       â””â”€â”€ chess_training_dag.py      #   Manual: train models â†’ monitor
â”‚
â”œâ”€â”€ infra/                             # â•â•â• INFRASTRUCTURE â•â•â•
â”‚   â””â”€â”€ docker-compose.yml             #   MinIO, PostgreSQL, MLflow, Airflow, API
â”‚
â”œâ”€â”€ tests/                             # â•â•â• TEST SUITE â•â•â•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_pgn_parser.py
â”‚   â”œâ”€â”€ test_tokenizer.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_transformer.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_drift.py
â”‚
â”œâ”€â”€ notebooks/                         # â•â•â• EXPLORATION â•â•â•
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ data/                              # â•â•â• DATA (git-ignored) â•â•â•
â”‚   â”œâ”€â”€ raw/                           #   Raw PGN files
â”‚   â”œâ”€â”€ interim/                       #   Intermediate artefacts
â”‚   â””â”€â”€ processed/                     #   Model-ready features & splits
â”‚
â”œâ”€â”€ artefacts/                         # â•â•â• MODEL ARTEFACTS (git-ignored) â•â•â•
â”‚   â”œâ”€â”€ models/                        #   Trained model checkpoints
â”‚   â””â”€â”€ tokenizers/                    #   Fitted tokenizer JSON
â”‚
â””â”€â”€ reports/                           # â•â•â• MONITORING REPORTS (git-ignored) â•â•â•
    â””â”€â”€ .gitkeep
```

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/nabin2004/chessMania.git
cd chessMania

# Create virtual environment
python -m venv .venv && source .venv/bin/activate

# Install with dev extras
make dev
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env with your credentials
```

### 3. Start Infrastructure

```bash
make infra-up    # Starts MinIO, PostgreSQL, MLflow, Airflow
```

| Service | URL |
|---|---|
| MinIO Console | http://localhost:9001 |
| PostgreSQL | localhost:5432 |
| MLflow UI | http://localhost:5000 |
| Airflow UI | http://localhost:8080 |
| API | http://localhost:8000 |

### 4. Ingest Data

Place Lichess PGN files in `data/raw/`, then:

```bash
make ingest      # Parse PGNs â†’ PostgreSQL + MinIO
make validate    # Run Great Expectations checks
```

### 5. Train Models

```bash
make train-xgb          # XGBoost baseline
make train-transformer  # Transformer sequence model
```

### 6. Serve

```bash
make serve   # Start FastAPI at localhost:8000
```

### 7. Monitor

```bash
make monitor  # Generate Evidently drift reports
```

---

## ğŸ”Œ API Endpoints

### `GET /health`
```json
{ "status": "ok", "models_loaded": ["xgboost", "transformer"] }
```

### `POST /predict/win`
Predict game outcome probabilities from tabular features.
```json
{
  "white_elo": 1500,
  "black_elo": 1450,
  "time_control": "300+3",
  "eco": "B20",
  "moves_played": 10
}
```
â†’ `{ "white_win": 0.52, "draw": 0.28, "black_win": 0.20, "predicted_result": "1-0" }`

### `POST /predict/next-move`
Suggest next moves from a partial game sequence.
```json
{
  "moves": ["e4", "e5", "Nf3"],
  "num_suggestions": 3,
  "temperature": 1.0
}
```
â†’ `{ "suggestions": [{"move": "Nc6", "probability": 0.35}, ...] }`

---

## ğŸ§ª Testing

```bash
make test    # pytest with coverage
make lint    # ruff + mypy
```

---

## ğŸ“Š MLOps Lifecycle Mapping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA LAYER                                â”‚
â”‚  Lichess PGNs â”€â”€â–º MinIO â”€â”€â–º Airflow ETL â”€â”€â–º PostgreSQL            â”‚
â”‚                              â”‚                                    â”‚
â”‚                    Great Expectations (validation)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PREPROCESSING                                 â”‚
â”‚  Tabular Features (ELO, ECO, TC)    â”‚   Sequence Tokenizer (SAN)  â”‚
â”‚  â”€â”€â–º XGBoost feature matrix         â”‚   â”€â”€â–º Integer token IDs     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MODEL DEVELOPMENT                               â”‚
â”‚  XGBoost Classifier                 â”‚   GPT-style Transformer     â”‚
â”‚  (Accuracy, F1, AUC)               â”‚   (Perplexity, MFU, Acc)    â”‚
â”‚                                     â”‚   + LoRA / QLoRA adapters   â”‚
â”‚                   MLflow Tracking                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SERVING                                      â”‚
â”‚  FastAPI + Uvicorn + Docker                                       â”‚
â”‚  /predict/win  (XGBoost)    â”‚   /predict/next-move  (Transformer) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MONITORING                                    â”‚
â”‚  Evidently AI                                                     â”‚
â”‚  â€¢ Tabular drift (ELO distributions, accuracy)                    â”‚
â”‚  â€¢ Sequence drift (invalid tokens, structural anomalies)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“œ License

MIT â€” see [LICENSE](LICENSE).
